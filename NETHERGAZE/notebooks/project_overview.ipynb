{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NETHERGAZE: Markerless Augmented Reality Pipeline\n",
        "\n",
        "**Author:** Milan Savard  \n",
        "**Course:** CS366 F25 Final Personal Project  \n",
        "**Date:** November 2025\n",
        "\n",
        "---\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "NETHERGAZE is a markerless augmented reality (AR) system built using computer vision techniques. Unlike traditional AR systems that rely on fiducial markers (like ArUco or AprilTags), NETHERGAZE uses **natural feature tracking** to estimate camera pose and overlay virtual content.\n",
        "\n",
        "### Key Technologies\n",
        "- **OpenCV** for image processing and computer vision\n",
        "- **ORB (Oriented FAST and Rotated BRIEF)** for feature detection and description\n",
        "- **Lucas-Kanade Optical Flow** for frame-to-frame feature tracking\n",
        "- **Essential Matrix + RANSAC** for robust pose estimation\n",
        "- **Temporal filtering** for smooth AR overlays\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [Architecture Overview](#1-architecture-overview)\n",
        "2. [Implementation Progress](#2-implementation-progress)\n",
        "3. [Component Deep Dive](#3-component-deep-dive)\n",
        "4. [Demo: Running the Pipeline](#4-demo-running-the-pipeline)\n",
        "5. [Configuration Options](#5-configuration-options)\n",
        "6. [Next Steps & Roadmap](#6-next-steps--roadmap)\n",
        "7. [References](#7-references)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Architecture Overview\n",
        "\n",
        "The NETHERGAZE pipeline consists of five main stages:\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚   Capture   â”‚ -> â”‚   Tracking   â”‚ -> â”‚ Pose Estimationâ”‚ -> â”‚   Overlay   â”‚ -> â”‚ Display â”‚\n",
        "â”‚  (video.py) â”‚    â”‚ (feature.py) â”‚    â”‚   (pose.py)    â”‚    â”‚ (overlay.py)â”‚    â”‚ (ui.py) â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Module Responsibilities\n",
        "\n",
        "| Module | File | Purpose |\n",
        "|--------|------|---------|  \n",
        "| **VideoProcessor** | `src/video.py` | Camera capture, preprocessing, backend selection |\n",
        "| **FeatureTracker** | `src/tracking/feature.py` | ORB detection, optical flow, keyframe management |\n",
        "| **PoseEstimator** | `src/pose.py` | Essential matrix, pose recovery, temporal filtering |\n",
        "| **OverlayRenderer** | `src/overlay.py` | 2D/3D overlay rendering, blending |\n",
        "| **UserInterface** | `src/ui.py` | Display window, keyboard controls |\n",
        "| **NETHERGAZEApp** | `src/main.py` | Pipeline orchestration, CLI interface |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Implementation Progress\n",
        "\n",
        "### âœ… Completed Components\n",
        "\n",
        "| Component | Status | Description |\n",
        "|-----------|--------|-------------|\n",
        "| Video Capture | âœ… Complete | Multi-backend support (AVFoundation, DirectShow, V4L2) |\n",
        "| Feature Tracking | âœ… Complete | ORB + optical flow with keyframe management |\n",
        "| Pose Estimation | âœ… Complete | Essential matrix decomposition with temporal smoothing |\n",
        "| Overlay Rendering | âœ… Complete | 2D primitives + 3D wireframes |\n",
        "| User Interface | âœ… Complete | OpenCV window with keyboard controls |\n",
        "| Pipeline Orchestration | âœ… Complete | CLI-driven main application |\n",
        "| Configuration System | âœ… Complete | JSON config with sensible defaults |\n",
        "\n",
        "### ðŸš§ In Progress / Planned\n",
        "\n",
        "| Component | Status | Priority |\n",
        "|-----------|--------|----------|\n",
        "| Camera Calibration Tool | ðŸš§ Planned | High |\n",
        "| Scale Recovery | ðŸš§ Partial | High |\n",
        "| Textured 3D Models | ðŸš§ Planned | Medium |\n",
        "| Integration Tests | ðŸš§ Planned | Medium |\n",
        "| SLAM Integration | ðŸš§ Future | Low |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Component Deep Dive\n",
        "\n",
        "Let's explore each component in detail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Add src to path for imports\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Navigate to project root\n",
        "notebook_dir = os.getcwd()\n",
        "project_root = os.path.dirname(notebook_dir) if 'notebooks' in notebook_dir else notebook_dir\n",
        "src_path = os.path.join(project_root, 'src')\n",
        "sys.path.insert(0, src_path)\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Source path: {src_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Feature Tracking\n",
        "\n",
        "The `FeatureTracker` class implements a hybrid approach:\n",
        "1. **Detection**: ORB features are detected when tracking is lost or features drop below threshold\n",
        "2. **Tracking**: Lucas-Kanade optical flow tracks features frame-to-frame (faster than re-detection)\n",
        "3. **Keyframes**: Best frames are stored for re-localization when tracking fails\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tracking.feature import FeatureTracker, TrackingConfiguration\n",
        "\n",
        "# View default configuration\n",
        "default_config = TrackingConfiguration()\n",
        "print(\"Feature Tracking Configuration:\")\n",
        "print(f\"  Method: {default_config.method}\")\n",
        "print(f\"  Max Features: {default_config.max_features}\")\n",
        "print(f\"  Use Optical Flow: {default_config.use_optical_flow}\")\n",
        "print(f\"  Optical Flow Window: {default_config.optical_flow_win_size}\")\n",
        "print(f\"  Reacquire Threshold: {default_config.reacquire_threshold}\")\n",
        "print(f\"  Keyframe Interval: {default_config.keyframe_interval}\")\n",
        "print(f\"  Max Keyframes: {default_config.max_keyframes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Pose Estimation\n",
        "\n",
        "The `PoseEstimator` class recovers camera motion from 2D-2D correspondences:\n",
        "\n",
        "1. **Essential Matrix**: Computed from matched points using RANSAC\n",
        "2. **Pose Recovery**: Decompose E into rotation (R) and translation (t)\n",
        "3. **Temporal Filtering**: EMA smoothing + outlier rejection for stable overlays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pose import PoseEstimator, PoseFilterConfig\n",
        "\n",
        "# View pose filter configuration\n",
        "filter_config = PoseFilterConfig()\n",
        "print(\"Pose Filter Configuration:\")\n",
        "print(f\"  Enable Smoothing: {filter_config.enable_smoothing}\")\n",
        "print(f\"  Smoothing Alpha (EMA): {filter_config.smoothing_alpha}\")\n",
        "print(f\"  Enable Outlier Rejection: {filter_config.enable_outlier_rejection}\")\n",
        "print(f\"  Max Translation Jump: {filter_config.max_translation_jump} m\")\n",
        "print(f\"  Max Rotation Jump: {filter_config.max_rotation_jump} rad\")\n",
        "print(f\"  Min Inliers Threshold: {filter_config.min_inliers_threshold}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Overlay Rendering\n",
        "\n",
        "The `OverlayRenderer` supports both 2D screen-space and 3D world-space overlays:\n",
        "\n",
        "**2D Overlays:**\n",
        "- Text labels\n",
        "- Rectangles, circles, lines\n",
        "- Polygons\n",
        "\n",
        "**3D Wireframe Objects:**\n",
        "- Cube, pyramid, grid\n",
        "- Coordinate axes (RGB = XYZ)\n",
        "- Custom wireframes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from overlay import OverlayRenderer, OverlayConfiguration\n",
        "\n",
        "# View overlay configuration\n",
        "overlay_config = OverlayConfiguration()\n",
        "print(\"Overlay Configuration:\")\n",
        "print(f\"  Enable 2D Overlays: {overlay_config.enable_2d_overlays}\")\n",
        "print(f\"  Enable 3D Overlays: {overlay_config.enable_3d_overlays}\")\n",
        "print(f\"  Default 3D Color: {overlay_config.default_3d_color} (BGR)\")\n",
        "print(f\"  Blend Alpha: {overlay_config.blend_alpha}\")\n",
        "print(f\"  Antialiasing: {overlay_config.antialiasing}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Camera Calibration\n",
        "\n",
        "The system uses a camera intrinsic matrix (K) for projection:\n",
        "\n",
        "```\n",
        "K = | fx   0  cx |\n",
        "    |  0  fy  cy |\n",
        "    |  0   0   1 |\n",
        "```\n",
        "\n",
        "Where:\n",
        "- `fx, fy` = focal lengths in pixels\n",
        "- `cx, cy` = principal point (image center)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import get_config\n",
        "import numpy as np\n",
        "\n",
        "# Load default calibration\n",
        "config = get_config()\n",
        "calib = config['calibration']\n",
        "\n",
        "K = np.array(calib['camera_matrix'])\n",
        "dist = np.array(calib['dist_coeffs'])\n",
        "\n",
        "print(\"Default Camera Matrix (K):\")\n",
        "print(K)\n",
        "print(f\"\\nFocal Length: fx={K[0,0]:.1f}, fy={K[1,1]:.1f} pixels\")\n",
        "print(f\"Principal Point: cx={K[0,2]:.1f}, cy={K[1,2]:.1f} pixels\")\n",
        "print(f\"\\nDistortion Coefficients: {dist}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Demo: Running the Pipeline\n",
        "\n",
        "### Command Line Usage\n",
        "\n",
        "```bash\n",
        "# Basic demo (uses examples/run_demo.py)\n",
        "cd NETHERGAZE\n",
        "python3 examples/run_demo.py\n",
        "\n",
        "# Full pipeline with CLI options\n",
        "python3 src/main.py                    # Default camera\n",
        "python3 src/main.py --camera 1         # Specific camera index\n",
        "python3 src/main.py --video demo.mp4   # Video file input\n",
        "python3 src/main.py --verbose          # Debug logging\n",
        "python3 src/main.py --config cfg.json  # Custom config file\n",
        "```\n",
        "\n",
        "### Keyboard Controls\n",
        "\n",
        "| Key | Action |\n",
        "|-----|--------|\n",
        "| `q` / `ESC` | Quit |\n",
        "| `m` | Toggle feature marker display |\n",
        "| `a` | Toggle pose axes display |\n",
        "| `p` | Pause/Resume |\n",
        "| `h` | Show help |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the main.py CLI help\n",
        "import subprocess\n",
        "result = subprocess.run(\n",
        "    ['python3', '../src/main.py', '--help'],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "print(result.stdout)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Configuration Options\n",
        "\n",
        "All parameters can be customized via JSON config file or modified in `src/utils.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from utils import get_config\n",
        "\n",
        "# Get full configuration\n",
        "config = get_config()\n",
        "\n",
        "# Pretty print\n",
        "print(\"Full Configuration:\")\n",
        "print(json.dumps(config, indent=2, default=str))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Configuration Sections\n",
        "\n",
        "| Section | Description |\n",
        "|---------|-------------|\n",
        "| `feature_tracking` | ORB detection and optical flow parameters |\n",
        "| `calibration` | Camera intrinsic matrix and distortion coefficients |\n",
        "| `pose_filter` | Temporal smoothing and outlier rejection settings |\n",
        "| `overlay` | 2D/3D rendering options |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Next Steps & Roadmap\n",
        "\n",
        "### High Priority\n",
        "\n",
        "#### 1. Camera Calibration Tool\n",
        "Create a utility to calibrate cameras using a chessboard pattern:\n",
        "\n",
        "```python\n",
        "# Planned: examples/calibrate_camera.py\n",
        "# - Capture N images of chessboard from different angles\n",
        "# - Detect corners using cv2.findChessboardCorners()\n",
        "# - Compute K and distortion using cv2.calibrateCamera()\n",
        "# - Save to JSON file\n",
        "```\n",
        "\n",
        "#### 2. Scale Recovery Enhancement\n",
        "Markerless tracking recovers pose up to an unknown scale. Options:\n",
        "- Known object size in scene\n",
        "- IMU integration for metric scale\n",
        "- Stereo camera setup\n",
        "\n",
        "### Medium Priority\n",
        "\n",
        "#### 3. Textured 3D Models\n",
        "Replace wireframes with proper 3D mesh rendering:\n",
        "- Load OBJ/PLY files\n",
        "- OpenGL integration for GPU rendering\n",
        "- Texture mapping\n",
        "\n",
        "#### 4. Integration Tests\n",
        "- Offline video playback for reproducible testing\n",
        "- Measure tracking stability metrics\n",
        "- Pose accuracy evaluation\n",
        "\n",
        "### Low Priority (Future)\n",
        "\n",
        "#### 5. SLAM Integration\n",
        "- Build persistent 3D map of environment\n",
        "- Loop closure detection\n",
        "- Long-term localization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Suggested Next Task: Camera Calibration Tool\n",
        "\n",
        "Here's a skeleton for the calibration utility:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Skeleton for camera calibration tool\n",
        "# TODO: Implement in examples/calibrate_camera.py\n",
        "\n",
        "calibration_skeleton = '''\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def calibrate_camera(image_paths, board_size=(9, 6), square_size=0.025):\n",
        "    \"\"\"\n",
        "    Calibrate camera from chessboard images.\n",
        "    \n",
        "    Args:\n",
        "        image_paths: List of paths to calibration images\n",
        "        board_size: (cols, rows) of internal chessboard corners\n",
        "        square_size: Physical size of chessboard square in meters\n",
        "    \n",
        "    Returns:\n",
        "        camera_matrix, dist_coeffs\n",
        "    \"\"\"\n",
        "    # Prepare object points (0,0,0), (1,0,0), (2,0,0), ...\n",
        "    objp = np.zeros((board_size[0] * board_size[1], 3), np.float32)\n",
        "    objp[:, :2] = np.mgrid[0:board_size[0], 0:board_size[1]].T.reshape(-1, 2)\n",
        "    objp *= square_size\n",
        "    \n",
        "    obj_points = []  # 3D points in world\n",
        "    img_points = []  # 2D points in image\n",
        "    \n",
        "    for path in image_paths:\n",
        "        img = cv2.imread(path)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        ret, corners = cv2.findChessboardCorners(gray, board_size, None)\n",
        "        if ret:\n",
        "            obj_points.append(objp)\n",
        "            corners2 = cv2.cornerSubPix(\n",
        "                gray, corners, (11, 11), (-1, -1),\n",
        "                (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "            )\n",
        "            img_points.append(corners2)\n",
        "    \n",
        "    ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
        "        obj_points, img_points, gray.shape[::-1], None, None\n",
        "    )\n",
        "    \n",
        "    return K, dist\n",
        "\n",
        "def save_calibration(K, dist, output_path):\n",
        "    \"\"\"Save calibration to JSON file.\"\"\"\n",
        "    data = {\n",
        "        \"camera_matrix\": K.tolist(),\n",
        "        \"dist_coeffs\": dist.flatten().tolist()\n",
        "    }\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "'''\n",
        "\n",
        "print(\"Camera Calibration Skeleton:\")\n",
        "print(calibration_skeleton)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. References\n",
        "\n",
        "### Papers and Books\n",
        "1. Multiple View Geometry - Hartley and Zisserman (Essential matrix, pose recovery)\n",
        "2. ORB: An efficient alternative to SIFT or SURF - Rublee et al., 2011\n",
        "3. Lucas-Kanade Optical Flow - Lucas and Kanade, 1981\n",
        "\n",
        "### OpenCV Documentation\n",
        "- Feature Detection: https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html\n",
        "- Camera Calibration: https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html\n",
        "- Pose Estimation: https://docs.opencv.org/4.x/d7/d53/tutorial_py_pose.html\n",
        "\n",
        "### Project Files\n",
        "- PROGRESS.md - Detailed implementation progress\n",
        "- TESTING.md - Testing procedures\n",
        "- TROUBLESHOOTING.md - Common issues and solutions\n",
        "- docs/design_overview.md - Architecture documentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "NETHERGAZE is a fully functional markerless AR pipeline with:\n",
        "\n",
        "âœ… **Real-time feature tracking** using ORB + optical flow  \n",
        "âœ… **Robust pose estimation** with temporal filtering  \n",
        "âœ… **Flexible overlay system** for 2D and 3D content  \n",
        "âœ… **CLI-driven application** with extensive configuration  \n",
        "\n",
        "**Next immediate steps:**\n",
        "1. Build camera calibration tool for accurate intrinsics\n",
        "2. Improve scale recovery for metric pose\n",
        "3. Add integration tests for stability verification\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
